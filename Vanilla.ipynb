{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import callbacks\n",
    "from keras.datasets import mnist\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RN_input_small = np.load('RN_input_small.npy')\n",
    "a_small = np.load('a_small.npy')\n",
    "print (RN_input_small.shape)\n",
    "print (a_small.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(a_small)\n",
    "train_labels = le.transform(a_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_labels)\n",
    "l = len(np.unique(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_sent_max_len = 12\n",
    "q_sent_max_len = 12\n",
    "embedding_size = 32\n",
    "LSTM_size = 256\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_RN_input(embedded_c, embedded_q, answer):\n",
    "    \"\"\"\n",
    "    Returns the input for RN which has dim (n, 190, 1536), \n",
    "    where n is the number of context and 190=20C2.\n",
    "    Input(s):\n",
    "    - embedded_c: list of context (up to 20 sentences) \n",
    "                  for each different question.  \n",
    "    - embedded_q: embedding for the related question to \n",
    "                  the given embedded_c.\n",
    "    - answer: corresponding answer to the embedded c and q.              \n",
    "    \"\"\"\n",
    "    object_pairs = []\n",
    "\n",
    "    for i in embedded_c:\n",
    "        object_pair = list(itertools.combinations(i, 2))\n",
    "        object_pairs.append(object_pair)\n",
    "    \n",
    "    rn_inputs = []\n",
    "    m = len(object_pairs)\n",
    "    z = np.zeros((m, 190, 1536))    \n",
    "    \n",
    "    for i, object_pair in enumerate(object_pairs):\n",
    "        n = len(object_pair)\n",
    "        for j in range(n):\n",
    "            l = np.array(object_pair[j][0] + object_pair[j][1] + embedded_q[i][0])\n",
    "#             z[i][j] = np.array(object_pair[j][0] + object_pair[j][1] + embedded_q[i][0])\n",
    "            z[i][j] = np.concatenate((object_pair[j][0], object_pair[j][1], embedded_q[i][0]))\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_input = Input(shape=(c_sent_max_len,))\n",
    "c_embed = Embedding(c_sent_max_len, embedding_size)(c_input)\n",
    "c_lstm = LSTM(LSTM_size, \n",
    "#               return_sequences=True,\n",
    "             )(c_embed)\n",
    "\n",
    "q_input = Input(shape=(q_sent_max_len,))\n",
    "q_embed = Embedding(q_sent_max_len, embedding_size)(q_input)\n",
    "q_lstm = LSTM(LSTM_size, \n",
    "#               return_sequences=True,\n",
    "             )(q_embed)\n",
    "\n",
    "# RN_inputs = Lambda(convert_to_RN_input, arguments={c_lstm,q_lstm})\n",
    "RN_inputs = concatenate([c_lstm, q_lstm])\n",
    "RN_inputs = Reshape((-1,512))(RN_inputs)\n",
    "# RN_inputs = Flatten()(RN_inputs)\n",
    "\n",
    "factor = 1\n",
    "\n",
    "g_units = [256,256,256,256]*factor\n",
    "\n",
    "g1 = Dense(g_units[0], activation='relu')(RN_inputs)\n",
    "g2 = Dense(g_units[1], activation='relu')(g1)\n",
    "g3 = Dense(g_units[2], activation='relu')(g2)\n",
    "g4 = Dense(g_units[3], activation='relu')(g3)\n",
    "g_sum = Lambda(lambda x : K.sum(x,axis=1))(g4)\n",
    "\n",
    "f_units = [256*factor, 512*factor, l]\n",
    "\n",
    "f1 = Dense(f_units[0], activation='relu')(g_sum)\n",
    "f2 = Dense(f_units[1], activation='relu')(f1)\n",
    "f3 = Dense(f_units[2], activation='softmax')(f2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[c_input,q_input], outputs = f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_77 (InputLayer)           (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_78 (InputLayer)           (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_77 (Embedding)        (None, 12, 32)       384         input_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_78 (Embedding)        (None, 12, 32)       384         input_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_77 (LSTM)                  (None, 256)          295936      embedding_77[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_78 (LSTM)                  (None, 256)          295936      embedding_78[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 512)          0           lstm_77[0][0]                    \n",
      "                                                                 lstm_78[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_33 (Reshape)            (None, 1, 512)       0           concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_212 (Dense)               (None, 1, 256)       131328      reshape_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_213 (Dense)               (None, 1, 256)       65792       dense_212[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_214 (Dense)               (None, 1, 256)       65792       dense_213[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_215 (Dense)               (None, 1, 256)       65792       dense_214[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)              (None, 256)          0           dense_215[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_216 (Dense)               (None, 256)          65792       lambda_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_217 (Dense)               (None, 512)          131584      dense_216[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_218 (Dense)               (None, 6)            3078        dense_217[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,121,798\n",
      "Trainable params: 1,121,798\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
